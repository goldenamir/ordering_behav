{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlalchemy in /Users/amir/opt/anaconda3/envs/ordering/lib/python3.9/site-packages (1.4.18)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/amir/opt/anaconda3/envs/ordering/lib/python3.9/site-packages (from sqlalchemy) (1.1.0)\n",
      "Requirement already satisfied: pandas in /Users/amir/opt/anaconda3/envs/ordering/lib/python3.9/site-packages (1.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/amir/opt/anaconda3/envs/ordering/lib/python3.9/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/amir/opt/anaconda3/envs/ordering/lib/python3.9/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /Users/amir/opt/anaconda3/envs/ordering/lib/python3.9/site-packages (from pandas) (1.20.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/amir/opt/anaconda3/envs/ordering/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "!pip install pandas\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///ordering.sqlite') # creating a database for query on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size_sql=50000\n",
    "batch_no=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for chunk in pd.read_csv('largefile.txt', sep = '\\t', header = None, names = ['id','date','data'], chunksize=chunk_size_sql,iterator=True):\n",
    "    chunk.to_sql('chunk_sql'+str(i), engine, if_exists='append')\n",
    "#     print(i)\n",
    "    i += 1\n",
    "    batch_no+=1\n",
    "    #print('index: {}'.format(batch_no))\n",
    "Size = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = engine.connect() # connection to the engine of the created datebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns name on the Table of SALLITE file\n",
    "\n",
    "# rs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "#  Ordering function\n",
    "\n",
    "#def mergeSort():\n",
    "Path = 'largefile.txt'\n",
    "data=pd.read_csv(Path, sep='\\t', header = None, usecols=[0,1])\n",
    "data.info(verbose=False, memory_usage='deep')\n",
    "\n",
    "data_modified=data.sort_values([0,1])\n",
    "data_modified = data_modified.drop(0, axis = 0)\n",
    "data_modified.columns = ['id', 'Date']\n",
    "data_modified.info(verbose=False, memory_usage='deep')\n",
    "\n",
    "data_modified.to_csv('data_modified.csv')\n",
    "data_modified.info(verbose=False, memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_sorted.to_csv('data_sorted.txt',index = False, header = False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 100 # this chunk size is for reading in the sql and saving \n",
    "\n",
    "Zeros = np.zeros((chunk_size,3)) # making zero series for making temp dataframe with chunk_size\n",
    "\n",
    "data_temp = pd.DataFrame(Zeros) # temp dataframe for saving results\n",
    "\n",
    "# print('data_temp: ',data_temp)\n",
    "\n",
    "data_frame_no = 0 # counter on data_frame_no for chaning every chunk_size\n",
    "\n",
    "no_chunk_sql = 51\n",
    "\n",
    "\n",
    "num_iter_data_modified = 0\n",
    " \n",
    "m = 0  # for counting every chunk_size\n",
    "\n",
    "for i in range(data_modified.shape[0]):    \n",
    "    start = time.time()\n",
    "    \n",
    "    j = data_modified.iloc[i, 0:2]  # values in data_modified in first and second columns\n",
    "#     print('j[0]: ',j[0])\n",
    "#     print('i: ',i)\n",
    "#     print('j[1]: ', j[1])\n",
    "    \n",
    "    ID = str(j[0]) \n",
    "#     print('ID: ',ID)\n",
    "    \n",
    "    DATE = j[1]\n",
    "#     print('Date: ',DATE)\n",
    "    \n",
    "    \n",
    "    for k in range(no_chunk_sql):\n",
    "        chunk_sql_count = 'chunk_sql'+str(k) # chunk of sql and its related number\n",
    "        #print('chunk_sql_count: ',chunk_sql_count)\n",
    "        a = con.execute('SELECT * from '+(chunk_sql_count)+' where id = '+'\\''+str(ID)+'\\''+ 'and date = '+str(DATE))\n",
    "        b = a.fetchall()\n",
    "        #b\n",
    "        if len(b)!=0:#######\n",
    "            \n",
    "#             print('chunk_sql_count: ',chunk_sql_count)\n",
    "            \n",
    "#             print(b[0][:])\n",
    "            \n",
    "            data_temp.iloc[m,0] = b[0][1]\n",
    "            data_temp.iloc[m,1] = b[0][2]\n",
    "            data_temp.iloc[m,2] = b[0][3]\n",
    "#             print(data_temp.iloc[m,:])\n",
    "            con.execute('DELETE FROM '+(chunk_sql_count)+' where id = '+'\\''+str(ID)+'\\''+ 'and date = '+str(DATE))\n",
    "            m += 1\n",
    "            num_iter_data_modified += 1\n",
    "            if num_iter_data_modified%chunk_size==0:\n",
    "                data_temp.to_csv('data_sorted_slice_'+str(data_frame_no)+'.txt',index = False, sep = '\\t') \n",
    "                data_temp.to_csv('output.txt',mode='a',index = False, header = False, sep = '\\t')\n",
    "#                 print(data_temp.head())\n",
    "                data_frame_no += 1\n",
    "                data_temp = pd.DataFrame(Zeros)\n",
    "                m -= chunk_size\n",
    "                num_iter_data_modified = 0\n",
    "                end = time.time()\n",
    "                print('[INFO]... '+str(data_frame_no) +' has been shaped!')\n",
    "                print(f\"Runtime of the program is {end - start}\")\n",
    "            break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amir\n",
      "k:  4\n",
      "0\n",
      "31602273\n",
      "lsipiymfqxpvo94adzfmrhw7zx3auiznha5a7gf60zgyhcq1bcpdtlc0xevnq8go10a7vvf2jdpmplqmmvmenzbp1yrzn4gat98xsi042n9vw6n172vxcvrsps4jhz3ccdkb7kxe6xs2qfhrdk77uo1fms5uokpuykm6cyayikx7ail6wmnkg4mo2yzlj5nsfe9qzb4u7vhlidljl6zrp9l48bur04f9swrhw9tskacgs1jjvbudus6g1251tmfv9ppef6rm9e9q1aiwbla171t6cztb8fmppm23bjoiv2hwusljs5804vz8dqirfqsj8mk4282m5qwpxe61elbdmfatds08vdxlih36at0o0yly3m18qgtdeec40omkg6dncbxt91vmn3dmciwq0ni3rhr3gng4yi01qo881y5mm83i4ex16g484fpxsr0bxkv3bdcfvibrq1oxvsazaexr1qaxl6wpkm5tb9jofmm1iz4twadf4dthpkw5trs3pme3fljspx9nfl3edmpgvpqy2ng8fz69n1m2afwld8crsvo5giegrn6dmr3a4t8ulf54odsvjg7869sab6hexahuuucmj1ezgw8i6v9dv7ma7oiwoowlkvoayu6qdfejt3d0b3bgslud6r7b4qlfcgzta8r1p4uvihufsvb8okq5ci7golf36nmqm8vrzzqv42ypkatr1i1uje6n2l61prgpaykcgoklbm5vo0dsp4dor5zvm26lydyvmtgkf3iszw32vm6tui5fjlbtyrfj0s8werhft1ci42ko\n"
     ]
    }
   ],
   "source": [
    "for k in range(51):\n",
    "    chunk_sql_count = 'chunk_sql'+str(k)\n",
    "    a = con.execute('SELECT * from '+(chunk_sql_count)+' where id = '+'\\''+str(ID)+'\\''+ 'and date = '+str(DATE))\n",
    "    \n",
    "    b = a.fetchall()\n",
    "    \n",
    "    if len(b)!=0:\n",
    "        print('Amir')\n",
    "        print('k: ', k)\n",
    "        print(b[0][1])\n",
    "        print(b[0][2])\n",
    "        print(b[0][3])\n",
    "#         con.execute('DELETE FROM '+(chunk_sql_count)+' where id = '+'\\''+str(ID)+'\\''+ 'and date = '+str(DATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = 0\n",
    "k = 4\n",
    "DATE = 31602273\n",
    "chunk_sql_count = 'chunk_sql'+str(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lsipiymfqxpvo94adzfmrhw7zx3auiznha5a7gf60zgyhcq1bcpdtlc0xevnq8go10a7vvf2jdpmplqmmvmenzbp1yrzn4gat98xsi042n9vw6n172vxcvrsps4jhz3ccdkb7kxe6xs2qfhrdk77uo1fms5uokpuykm6cyayikx7ail6wmnkg4mo2yzlj5nsfe9qzb4u7vhlidljl6zrp9l48bur04f9swrhw9tskacgs1jjvbudus6g1251tmfv9ppef6rm9e9q1aiwbla171t6cztb8fmppm23bjoiv2hwusljs5804vz8dqirfqsj8mk4282m5qwpxe61elbdmfatds08vdxlih36at0o0yly3m18qgtdeec40omkg6dncbxt91vmn3dmciwq0ni3rhr3gng4yi01qo881y5mm83i4ex16g484fpxsr0bxkv3bdcfvibrq1oxvsazaexr1qaxl6wpkm5tb9jofmm1iz4twadf4dthpkw5trs3pme3fljspx9nfl3edmpgvpqy2ng8fz69n1m2afwld8crsvo5giegrn6dmr3a4t8ulf54odsvjg7869sab6hexahuuucmj1ezgw8i6v9dv7ma7oiwoowlkvoayu6qdfejt3d0b3bgslud6r7b4qlfcgzta8r1p4uvihufsvb8okq5ci7golf36nmqm8vrzzqv42ypkatr1i1uje6n2l61prgpaykcgoklbm5vo0dsp4dor5zvm26lydyvmtgkf3iszw32vm6tui5fjlbtyrfj0s8werhft1ci42ko\n"
     ]
    }
   ],
   "source": [
    "a = con.execute('SELECT * FROM '+(chunk_sql_count) +\n",
    "                            ' WHERE id = '+'\\''+str(ID)+'\\'' + 'AND date = '+str(DATE))\n",
    "b = a.fetchall()\n",
    "print(b[0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
